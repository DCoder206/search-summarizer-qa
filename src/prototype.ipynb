{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline,BartTokenizer,AutoTokenizer,AutoModelForQuestionAnswering,AutoModelForSeq2SeqLM\n",
    "import requests,re,nltk\n",
    "from trl import PPOConfig,PPOTrainer\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(html):\n",
    "    text = re.sub(r'<[^>]+>|[<>\\'\"]|[^a-zA-Z0-9,.?:]', '', html)\n",
    "    return text\n",
    "user_query = input(\"Enter your query: \")\n",
    "search_url = f\"https://www.google.com/search?q={\"+\".join(user_query.split(\" \"))}\"\n",
    "response = requests.get(search_url,headers={\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:135.0) Gecko/20100101 Firefox/135.0\"\n",
    "})\n",
    "page_text = extract_text(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    f\"extract the information relevant to the query '{user_query}'\"\n",
    "    f\"from the following text:\\n\\n{page_text}\"\n",
    ")\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "summarizer = pipeline(\"summarization\",model=\"facebook/bart-large-cnn\")\n",
    "summary = summarizer(prompt,max_length=200,min_length=50,do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text,tokenizer,max_tokens=512):\n",
    "    sentences = nltk.sent_tokenize(text,language=\"english\")\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for sentence in sentences:\n",
    "        sentence_tokens = tokenizer.tokenize(sentence,truncation=False)\n",
    "        sentence_token_count = len(sentence_tokens)\n",
    "        if current_length + sentence_token_count <= max_tokens:\n",
    "            current_chunk.append(sentence)\n",
    "            current_length += sentence_token_count\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(\" \".join(current_chunk))\n",
    "                current_chunk = [sentence]\n",
    "                current_length = sentence_token_count\n",
    "            else:\n",
    "                chunks.append(sentence[:500])\n",
    "                current_chunk = []\n",
    "                current_length = 0\n",
    "    if current_chunk: chunks.append(\" \".join(current_chunk))\n",
    "    return chunks\n",
    "def summarize_large_text(text,model_name=\"facebook/bart-large-cnn\",max_chunk_tokens=512):\n",
    "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "    summarizer = pipeline(\"summarization\",model=model_name)\n",
    "    chunks = chunk_text(text,tokenizer,max_chunk_tokens)\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        summary = summarizer(\n",
    "            chunk,\n",
    "            max_length=200,\n",
    "            min_length=50,\n",
    "            do_sample=False,\n",
    "            truncation=True\n",
    "        )[0][\"summary_text\"]\n",
    "        summaries.append(summary)\n",
    "    final_summary = \" \".join(summaries)\n",
    "    while len(tokenizer.tokenize(final_summary)) > 512:\n",
    "        final_summary = summarizer(\n",
    "            final_summary,\n",
    "            max_length=512,\n",
    "            min_length=100,\n",
    "            do_sample=False,\n",
    "            truncation=True\n",
    "        )[0][\"summary_text\"]\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumry = summarize_large_text(page_text)\n",
    "qa_pipeline = pipeline(\"question-answering\",model=\"distilbert-base-cased-distilled-squad\")\n",
    "qa_result = qa_pipeline(question=user_query,context=sumry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qa_result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RLHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_feedback():\n",
    "    feedback = input(\"Please rate the answer on a scale from 1 (poor) to 5 (excellent): \")\n",
    "    try: return int(feedback)\n",
    "    except ValueError: return 3\n",
    "def compute_reward(fbk):\n",
    "    return (fbk - 3) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_model_path = \"../models/fine_tuned_bart\"\n",
    "if exists(summarizer_model_path):\n",
    "    model_summarizer = AutoModelForSeq2SeqLM.from_pretrained(summarizer_model_path)\n",
    "    tokenizer_summarizer = BartTokenizer.from_pretrained(summarizer_model_path)\n",
    "else:\n",
    "    model_summarizer = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "    tokenizer_summarizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "ppo_config_sum = PPOConfig(learning_rate=4e-5,batch_size=1,mini_batch_size=1)\n",
    "ppo_trainer_sum = PPOTrainer(ppo_config_sum, model_summarizer, tokenizer_summarizer)\n",
    "\n",
    "qa_model_path = \"../models/fine_tuned_qa\"\n",
    "if exists(qa_model_path):\n",
    "    model_qa = AutoModelForQuestionAnswering.from_pretrained(qa_model_path)\n",
    "    tokenizer_qa = AutoTokenizer.from_pretrained(qa_model_path)\n",
    "else:\n",
    "    model_qa = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "    tokenizer_qa = AutoTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "ppo_config_qa = PPOConfig(learning_rate=4e-3,batch_size=1,mini_batch_size=1)\n",
    "ppo_trainer_qa = PPOTrainer(ppo_config_qa,model_qa,tokenizer_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFeedback for Summary:\")\n",
    "fbk_sum = user_feedback(\"Rate the summary extraction (1-5): \")\n",
    "reward_sum = compute_reward(fbk_sum)\n",
    "\n",
    "print(\"\\nFeedback for QA:\")\n",
    "fbk_qa = user_feedback(\"Rate the QA answer (1-5): \")\n",
    "reward_qa = compute_reward(fbk_qa)\n",
    "\n",
    "ppo_trainer_sum.step([prompt], [sumry], [reward_sum])\n",
    "model_summarizer.save_pretrained(summarizer_model_path)\n",
    "tokenizer_summarizer.save_pretrained(summarizer_model_path)\n",
    "\n",
    "qa_prompt = f\"Question: {user_query}\\nContext: {sumry}\"\n",
    "\n",
    "ppo_trainer_qa.step([qa_prompt], [sumry], [reward_qa])\n",
    "model_qa.save_pretrained(qa_model_path)\n",
    "tokenizer_qa.save_pretrained(qa_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
